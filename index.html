<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ishan Dave</title>
  
  <meta name="author" content="Ishan Dave">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ishan Dave</name>
              </p>
              <p style="font-size:15px">I am a fifth-year Ph.D. student in the Center for Research in Computer Vision (CRCV), University of Central Florida (UCF), advised by <a href="https://www.crcv.ucf.edu/person/mubarak-shah/" style="font-size:15px">Prof. Mubarak Shah</a>. </a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:ishandave95@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=fWu6sFgAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/daveishan">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ishan-dave-crcv/">LinkedIn</a> &nbsp/&nbsp
                <a href="data/CVPublic_Ishan_27Aug23.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ishan_pic-modified.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ishan_pic-modified.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Work Experience</heading>
            </td>
          </tr>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:10px;width:25%;vertical-align:top">
		<img src='images/Adobe-logo.png' style="width:100%;">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Research Scientist/ Engineer Intern</strong>
                <br> Adobe Inc., San Jose, California, USA. May 2023- Present
                <br> Host: <a href="https://sjenni.github.io/">Simon Jenni, </a>
                <a href="https://fabiancaba.com/">Fabian Caba</a>
                <p></p>
                <p> Temporal alignment for fine-grained video understanding</p>
              </td>
            </tr>
          </tr>
          </table>
	 <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
               <td style="padding:10px;width:25%;vertical-align:top">
		<img src='images/Adobe-logo.png' style="width:100%;">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Research Scientist Intern</strong>
                <br> Adobe Inc., Remote, USA. May 2022 - Nov 2022
                <br> Host: <a href="https://sjenni.github.io/">Simon Jenni</a>
                <p></p>
                <p> Self-supervised Video Representation Learning</p>
              </td>
            </tr>
          </tr>
          </table>

         

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have a broad interest in computer vision and machine learning. My current research mainly focuses on video representation learning with limited labels (self/semi-supervised learning), action recognition, and privacy preservation in video understanding tasks. I have also worked on various robotics-related vision tasks like event-camera-based action recognition and drone-to-drone detections from videos. 
                Below is a selected list of my works.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <div class="one">
	            <img src='images/timebalance_cvpr2023.png' width="180">
	        </div>
	    </td>
	    <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="LINK_TO_PAPER">
            <papertitle>TimeBalance: Temporally-Invariant and Temporally-Distinctive Video Representations for Semi-Supervised Action Recognition</papertitle>
        </a>
        <br>
        <strong>Ishan Rajendrakumar Dave</strong>, 
        Mamshad Nayeem Rizve, 
        Chen Chen, 
        Mubarak Shah.
        <br>
        <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
        <br>
        <a href="LINK_TO_PAPER">paper</a> &nbsp/&nbsp <a href="LINK_TO_CODE">code</a>
    	</td>
	</tr>

	<tr onmouseout="mira_stop()" onmouseover="mira_start()">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <div class="one">
	            <img src='images/transvisdrone_icra23.png' width="180">
	        </div>
	    </td>
	    <td style="padding:20px;width:75%;vertical-align:middle">
	        <a href="LINK_TO_PAPER">
	            <papertitle>Transvisdrone: Spatio-temporal Transformer for Vision-based Drone-to-drone Detection in Aerial Videos</papertitle>
	        </a>
	        <br>
	        Tushar Sangam, 
	        </strong>,Ishan Rajendrakumar Dave</strong>,, 
	        Waqas Sultani, 
	        Mubarak Shah.
	        <br>
	        <em>2023 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023
	        <br>
	        <a href="LINK_TO_PAPER">paper</a> &nbsp/&nbsp <a href="LINK_TO_CODE">code</a>
	    </td>
	</tr>

	

	<tr onmouseout="mira_stop()" onmouseover="mira_start()">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <div class="one">
	            <img src='images/Spact-pic.JPG' width="180">
	        </div>
	    </td>
	    <td style="padding:20px;width:75%;vertical-align:middle">
	        <a href="LINK_TO_PAPER">
	            <papertitle>Spact: Self-supervised Privacy Preservation for Action Recognition</papertitle>
	        </a>
	        <br>
	        <strong>Ishan Rajendrakumar Dave</strong>, 
	        Chen Chen, 
	        Mubarak Shah.
	        <br>
	        <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
	        <br>
	        <a href="LINK_TO_PAPER">paper</a> &nbsp/&nbsp <a href="LINK_TO_CODE">code</a>
	    </td>
	</tr>

	<tr onmouseout="mira_stop()" onmouseover="mira_start()">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <div class="one">
	            <img src='images/gabriellav2_wacv22.png' width="180">
	        </div>
	    </td>
	    <td style="padding:20px;width:75%;vertical-align:middle">
	        <a href="LINK_TO_PAPER">
	            <papertitle>Gabriellav2: Towards Better Generalization in Surveillance Videos for Action Detection</papertitle>
	        </a>
	        <br>
	        <strong>Ishan Dave</strong>, 
	        Zacchaeus Scheffer, 
	        Akash Kumar, 
	        Sarah Shiraz, 
	        Yogesh Singh Rawat, 
	        Mubarak Shah.
	        <br>
	        <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2022
	        <br>
	        <a href="LINK_TO_PAPER">paper</a> &nbsp/&nbsp <a href="LINK_TO_CODE">code</a>
	    </td>
	</tr>

	
		
	<tr onmouseout="mira_stop()" onmouseover="mira_start()">
	    <td style="padding:5px;width:25%;vertical-align:middle">
	        <div class="one">
	            <img src='images/tclr_cviu2022.png' width="180">
	        </div>
	        <script type="text/javascript">
	            function mira_start() {
	                document.getElementById('mira_image').style.opacity = "1";
	            }
	
	            function mira_stop() {
	                document.getElementById('mira_image').style.opacity = "0";
	            }
	            mira_stop()
	        </script>
	    </td>
	    <td style="padding:20px;width:75%;vertical-align:middle">
	        <a href="https://www.sciencedirect.com/science/article/pii/S1077314222000376">
	            <papertitle>TCLR: Temporal Contrastive Learning for Video Representation</papertitle>
	        </a>
	        <br>
	        <strong>Ishan Dave</strong>,
	        Rohit Gupta, 
	        Mamshad Nayeem Rizve, 
	        Mubarak Shah.
	        <br>
	        <em>Computer Vision and Image Understanding (<strong>CVIU</strong>)</em>, 2022
	        <br>
	       <em><strong><font color="red">(100+ citations, Among the top-10 most downloaded papers in CVIU)</font></strong></em>
               <br>
	        <a href="https://arxiv.org/pdf/2101.07974.pdf">paper</a> &nbsp/&nbsp
	        <a href="https://github.com/DAVEISHAN/TCLR">code</a>
	        <p></p>
	        <p>
	            We propose a new temporal contrastive learning framework for self-supervised video representation learning, consisting of two novel losses that aim to increase the temporal diversity of learned features. The framework achieves state-of-the-art results on various downstream video understanding tasks, including significant improvement in fine-grained action classification for visually similar classes.
	        </p>
	    </td>
	</tr>
		
	<tr onmouseout="mira_stop()" onmouseover="mira_start()">
	    <td style="padding:5px;width:25%;vertical-align:middle">
	        <div class="one">
	            <img src='images/tclr_cviu2022.png' width="180">
	        </div>
	        <script type="text/javascript">
	            function mira_start() {
	                document.getElementById('mira_image').style.opacity = "1";
	            }
	
	            function mira_stop() {
	                document.getElementById('mira_image').style.opacity = "0";
	            }
	            mira_stop()
	        </script>
	    </td>
	    <td style="padding:20px;width:75%;vertical-align:middle">
	        <a href="https://www.sciencedirect.com/science/article/pii/S1077314222000376">
	            <papertitle>TCLR: Temporal Contrastive Learning for Video Representation</papertitle>
	        </a>
	        <br>
	        <strong>Ishan Dave</strong>,
	        Rohit Gupta, 
	        Mamshad Nayeem Rizve, 
	        Mubarak Shah.
	        <br>
	        <em>Computer Vision and Image Understanding (<strong>CVIU</strong>)</em>, 2022
	        <br>
	       <em><strong><font color="red">(100+ citations, Among the top-10 most downloaded papers in CVIU)</font></strong></em>
               <br>
	        <a href="https://arxiv.org/pdf/2101.07974.pdf">paper</a> &nbsp/&nbsp
	        <a href="https://github.com/DAVEISHAN/TCLR">code</a>
	        <p></p>
	        <p>
	            We propose a new temporal contrastive learning framework for self-supervised video representation learning, consisting of two novel losses that aim to increase the temporal diversity of learned features. The framework achieves state-of-the-art results on various downstream video understanding tasks, including significant improvement in fine-grained action classification for visually similar classes.
	        </p>
	    </td>
	</tr>
          
				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Reviewing experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
		<a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, CVPR 2022, 2023</a><br>
		<a href="https://iccv2023.thecvf.com/">Reviewer, ICCV 2023</a>
 		<br>	
	      	<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">Reviewer, IEEE Transaction on Image Processing</a><br>
	        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">Reviewer, IEEE Transaction on Pattern Analysis and Machine Intelligence</a>
              <br>
              <br>
             
		    
            </td>
          </tr>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Mentor in NSF-REU</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/NSF_svg.png" width="50%" alt="NSF Image"></td>
            <td width="75%" valign="center">
		<a href="https://www.crcv.ucf.edu/nsf-projects/reu/reu-2022/">Kevin Chung, REU 2022</a>
	        <br>

		<a href="https://www.crcv.ucf.edu/nsf-projects/reu/reu-2021/">Ethan Thomas, REU 2021</a>
		<br>
		<a href="https://www.crcv.ucf.edu/nsf-projects/reu/reu-2020/">Kali Carter, REU 2020</a>

              <br>
              <br>
             
		    
            </td>
          </tr>

		
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
